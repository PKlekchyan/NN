{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "Клекчян Павел \"Intro to NN 4 (HW)\"",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "l4VAzKlG8aHj"
      },
      "source": [
        "## Neural Part Of Speech Tagging\n",
        "\n",
        "Теперь мы собираемся решить ту же проблему тегирования POS с помощью нейронных сетей. \n",
        "<img src=https://i.stack.imgur.com/6pdIT.png width=320>\n",
        "\n",
        "С точки зрения глубокого обучения это задача прогнозирования последовательности выходных данных, выровненной с последовательностью входных данных. Есть несколько задач, соответствующих этой формулировке:\n",
        "* Маркировка частей речи - вспомогательная задача для многих проблем НЛП\n",
        "* Распознавание именованных сущностей — для чат-ботов и поисковых роботов\n",
        "* Предсказание структуры белка - для биоинформатики "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnu9D3YZoH2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f9070ee-a3f5-4806-f06a-90c084c190ae"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "yxFUBtb88aHq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51812d2b-da79-4945-f505-6ac4bc29549f"
      },
      "source": [
        "import nltk\n",
        "import sys\n",
        "import numpy as np\n",
        "\n",
        "nltk.download('brown')\n",
        "nltk.download('universal_tagset')\n",
        "data = nltk.corpus.brown.tagged_sents(tagset='universal')\n",
        "all_tags = ['#EOS#','#UNK#','ADV', 'NOUN', 'ADP', 'PRON', 'DET', '.', 'PRT', 'VERB', 'X', 'NUM', 'CONJ', 'ADJ']\n",
        "\n",
        "data = np.array([ [(word.lower(),tag) for word,tag in sentence] for sentence in data ])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMsmGWqW48N1",
        "outputId": "a5d5f5e6-224c-4787-d404-13452573c5ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('the', 'DET'), ('fulton', 'NOUN'), ('county', 'NOUN'), ('grand', 'ADJ'), ('jury', 'NOUN'), ('said', 'VERB'), ('friday', 'NOUN'), ('an', 'DET'), ('investigation', 'NOUN'), ('of', 'ADP'), (\"atlanta's\", 'NOUN'), ('recent', 'ADJ'), ('primary', 'NOUN'), ('election', 'NOUN'), ('produced', 'VERB'), ('``', '.'), ('no', 'DET'), ('evidence', 'NOUN'), (\"''\", '.'), ('that', 'ADP'), ('any', 'DET'), ('irregularities', 'NOUN'), ('took', 'VERB'), ('place', 'NOUN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq_OXuD38aHs"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_data, test_data = train_test_split(data,test_size=0.25,random_state=42)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAlXrDmU8aHs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "outputId": "fe14f252-f627-4f40-e539-b85c6911c76b"
      },
      "source": [
        "from IPython.display import HTML, display\n",
        "def draw(sentence):\n",
        "    words,tags = zip(*sentence)\n",
        "    display(HTML('<table><tr>{tags}</tr>{words}<tr></table>'.format(\n",
        "                words = '<td>{}</td>'.format('</td><td>'.join(words)),\n",
        "                tags = '<td>{}</td>'.format('</td><td>'.join(tags)))))\n",
        "    \n",
        "    \n",
        "draw(data[11])\n",
        "draw(data[10])\n",
        "draw(data[7])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table><tr><td>NOUN</td><td>ADP</td><td>NOUN</td><td>NOUN</td><td>NOUN</td><td>NOUN</td><td>VERB</td><td>ADV</td><td>VERB</td><td>ADP</td><td>DET</td><td>ADJ</td><td>NOUN</td><td>.</td></tr><td>implementation</td><td>of</td><td>georgia's</td><td>automobile</td><td>title</td><td>law</td><td>was</td><td>also</td><td>recommended</td><td>by</td><td>the</td><td>outgoing</td><td>jury</td><td>.</td><tr></table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table><tr><td>PRON</td><td>VERB</td><td>ADP</td><td>DET</td><td>NOUN</td><td>.</td><td>VERB</td><td>NOUN</td><td>PRT</td><td>VERB</td><td>.</td><td>DET</td><td>NOUN</td><td>.</td></tr><td>it</td><td>urged</td><td>that</td><td>the</td><td>city</td><td>``</td><td>take</td><td>steps</td><td>to</td><td>remedy</td><td>''</td><td>this</td><td>problem</td><td>.</td><tr></table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table><tr><td>NOUN</td><td>VERB</td></tr><td>merger</td><td>proposed</td><tr></table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAViiL2C8aHt"
      },
      "source": [
        "### Построение словарей\n",
        "\n",
        "Как и раньше, нам нужно построить отображение токенов на целочисленные идентификаторы. На этот раз наша модель работает на уровне слов, обрабатывая одно слово за шаг RNN. Это означает, что нам придется иметь дело с гораздо большим словарным запасом.\n",
        "\n",
        "К счастью для нас, мы получаем эти слова только в качестве входных данных, то есть нам не нужно их предсказывать. Это означает, что мы можем иметь большой словарный запас бесплатно, используя встраивание слов. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ZXK_k-mo8aHt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dcd2b5a-7004-4bf9-fb4b-c2b4032e999e"
      },
      "source": [
        "from collections import Counter\n",
        "word_counts = Counter()\n",
        "for sentence in data:\n",
        "    words,tags = zip(*sentence)\n",
        "    word_counts.update(words)\n",
        "\n",
        "all_words = ['#EOS#','#UNK#'] + list(list(zip(*word_counts.most_common(10000)))[0])\n",
        "\n",
        "# Давайте измерим, какая часть слов данных находится в словаре \n",
        "print(\"Coverage = %.5f\" % (float(sum(word_counts[w] for w in all_words)) / sum(word_counts.values())))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coverage = 0.92876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "T0hee8L88aHt"
      },
      "source": [
        "from collections import defaultdict\n",
        "word_to_id = defaultdict(lambda:1, { word: i for i, word in enumerate(all_words) })\n",
        "tag_to_id = { tag: i for i, tag in enumerate(all_tags)}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCmGbwpP8aHu"
      },
      "source": [
        "Конвертируем слова и теги в матрицу фиксированного размера"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "X7kx6jWn8aHu"
      },
      "source": [
        "def to_matrix(lines, token_to_id, max_len=None, pad=0, dtype='int32', time_major=False):\n",
        "    \"\"\"Converts a list of names into rnn-digestable matrix with paddings added after the end\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len,lines))\n",
        "    matrix = np.empty([len(lines), max_len],dtype)\n",
        "    matrix.fill(pad)\n",
        "\n",
        "    for i in range(len(lines)):\n",
        "        line_ix = list(map(token_to_id.__getitem__,lines[i]))[:max_len]\n",
        "        matrix[i,:len(line_ix)] = line_ix\n",
        "\n",
        "    return matrix.T if time_major else matrix\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "BCaE-i5u8aHu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feef3d8d-114f-4173-dac6-af90a7509893"
      },
      "source": [
        "batch_words, batch_tags = zip(*[zip(*sentence) for sentence in data[-3:]])\n",
        "\n",
        "print(\"Word ids:\")\n",
        "print(to_matrix(batch_words, word_to_id))\n",
        "print(\"Tag ids:\")\n",
        "print(to_matrix(batch_tags, tag_to_id))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word ids:\n",
            "[[   2 3057    5    2 2238 1334 4238 2454    3    6   19   26 1070   69\n",
            "     8 2088    6    3    1    3  266   65  342    2    1    3    2  315\n",
            "     1    9   87  216 3322   69 1558    4    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0]\n",
            " [  45   12    8  511 8419    6   60 3246   39    2    1    1    3    2\n",
            "   845    1    3    1    3   10 9910    2    1 3470    9   43    1    1\n",
            "     3    6    2 1046  385   73 4562    3    9    2    1    1 3250    3\n",
            "    12   10    2  861 5240   12    8 8936  121    1    4]\n",
            " [  33   64   26   12  445    7 7346    9    8 3337    3    1 2811    3\n",
            "     2  463  572    2    1    1 1649   12    1    4    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0]]\n",
            "Tag ids:\n",
            "[[ 6  3  4  6  3  3  9  9  7 12  4  5  9  4  6  3 12  7  9  7  9  8  4  6\n",
            "   3  7  6 13  3  4  6  3  9  4  3  7  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0]\n",
            " [ 5  9  6  9  3 12  6  3  7  6 13  3  7  6 13  3  7 13  7  5  9  6  3  3\n",
            "   4  6 13  3  7 12  6  3  6 13  3  7  4  6  3  9  3  7  9  4  6 13  3  9\n",
            "   6  3  2 13  7]\n",
            " [ 4  6  5  9 13  4  3  4  6 13  7 13  3  7  6  3  4  6 13  3  3  9  9  7\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "_oK_i5Xa8aHv"
      },
      "source": [
        "### Построим модель\n",
        "\n",
        "В отличие от нашей предыдущей лаборатории, на этот раз мы сосредоточимся на высокоуровневом интерфейсе keras для рекуррентных нейронных сетей. Это настолько просто, насколько вы можете получить с помощью RNN, хотя и несколько ограничено для сложных задач, таких как seq2seq.\n",
        "\n",
        "По умолчанию все keras RNN применяются ко всей последовательности входных данных и создают последовательность скрытых состояний `(return_sequences=True` или только последнее скрытое состояние `(return_sequences=False)`. Все повторения происходят под капотом.\n",
        "\n",
        "В верхней части нашей модели нам нужно применить плотный слой к каждому временному шагу независимо. На данный момент keras.layers.Dense по умолчанию применяется один раз ко всем объединенным временным шагам. Мы используем __keras.layers.TimeDistributed__ для изменения плотного слоя, чтобы он применялся как к пакетной, так и к временной осям. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQeb8d5j8aHv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d48b5689-311c-412a-f385-caae0be7f421"
      },
      "source": [
        "import keras\n",
        "import keras.layers as L\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(L.InputLayer([None],dtype='int32'))\n",
        "model.add(L.Embedding(len(all_words),50))\n",
        "model.add(L.SimpleRNN(64,return_sequences=True))\n",
        "\n",
        "# Добавим верхний слой, который предсказывает вероятности тегов \n",
        "stepwise_dense = L.Dense(len(all_tags),activation='softmax')\n",
        "stepwise_dense = L.TimeDistributed(stepwise_dense)\n",
        "model.add(stepwise_dense)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQbJqM2n8aHv"
      },
      "source": [
        "__Training:__ в этом случае мы не хотим заранее подготавливать весь набор обучающих данных. Основная причина в том, что длина каждого пакета зависит от максимальной длины предложения в пакете. Это оставляет нам два варианта: использовать собственный обучающий код, как на предыдущем семинаре, или использовать генераторы.\n",
        "\n",
        "Модели Keras имеют метод __`model.fit_generator`__, который принимает генератор Python, выдающий по одному пакету за раз. Но сначала нам нужно реализовать такой генератор: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "kpeMsDi18aHw"
      },
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "BATCH_SIZE=32\n",
        "def generate_batches(sentences,batch_size=BATCH_SIZE,max_len=None,pad=0):\n",
        "    assert isinstance(sentences,np.ndarray),\"Make sure sentences is q numpy array\"\n",
        "    \n",
        "    while True:\n",
        "        indices = np.random.permutation(np.arange(len(sentences)))\n",
        "        for start in range(0,len(indices)-1,batch_size):\n",
        "            batch_indices = indices[start:start+batch_size]\n",
        "            batch_words,batch_tags = [],[]\n",
        "            for sent in sentences[batch_indices]:\n",
        "                words,tags = zip(*sent)\n",
        "                batch_words.append(words)\n",
        "                batch_tags.append(tags)\n",
        "\n",
        "            batch_words = to_matrix(batch_words,word_to_id,max_len,pad)\n",
        "            batch_tags = to_matrix(batch_tags,tag_to_id,max_len,pad)\n",
        "\n",
        "            batch_tags_1hot = to_categorical(batch_tags,len(all_tags)).reshape(batch_tags.shape+(-1,))\n",
        "            yield batch_words,batch_tags_1hot\n",
        "        "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYoR9vgn8aHw"
      },
      "source": [
        "__Callbacks:__ Еще одна вещь, которая нам нужна, — это измерение производительности модели. Сложность заключается не в том, чтобы считать точность после окончания предложения (при заполнении), а в том, чтобы убедиться, что мы считаем все данные проверки ровно один раз.\n",
        "\n",
        "Хотя нет ничего невозможного в том, чтобы убедить Keras сделать все это, мы можем также написать собственный обратный вызов, который сделает это.\n",
        "Обратные вызовы Keras позволяют вам написать собственный код, который будет запускаться один раз в каждую эпоху или каждый мини-пакет. Мы определим его через LambdaCallback "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "CC8woNtV8aHx"
      },
      "source": [
        "def compute_test_accuracy(model):\n",
        "    test_words,test_tags = zip(*[zip(*sentence) for sentence in test_data])\n",
        "    test_words,test_tags = to_matrix(test_words,word_to_id),to_matrix(test_tags,tag_to_id)\n",
        "\n",
        "    # Предскажем теговые вероятности формы  [batch,time,n_tags]\n",
        "    predicted_tag_probabilities = model.predict(test_words,verbose=1)\n",
        "    predicted_tags = predicted_tag_probabilities.argmax(axis=-1)\n",
        "\n",
        "    # Вычислим accuracy, исключая padding \n",
        "    numerator = np.sum(np.logical_and((predicted_tags == test_tags),(test_words != 0)))\n",
        "    denominator = np.sum(test_words != 0)\n",
        "    return float(numerator)/denominator\n",
        "\n",
        "\n",
        "class EvaluateAccuracy(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self,epoch,logs=None):\n",
        "        sys.stdout.flush()\n",
        "        print(\"\\nMeasuring validation accuracy...\")\n",
        "        acc = compute_test_accuracy(self.model)\n",
        "        print(\"\\nValidation accuracy: %.5f\\n\"%acc)\n",
        "        sys.stdout.flush()\n",
        "        "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "5eJGEWu58aHx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5356119-ac68-4954-c171-832a28aee187"
      },
      "source": [
        "model.compile('adam','categorical_crossentropy')\n",
        "\n",
        "model.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n",
        "                    callbacks=[EvaluateAccuracy()], epochs=5,)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Epoch 1/5\n",
            "1344/1343 [==============================] - 38s 29ms/step - loss: 0.2523\n",
            "\n",
            "Measuring validation accuracy...\n",
            "14335/14335 [==============================] - 6s 413us/step\n",
            "\n",
            "Validation accuracy: 0.94044\n",
            "\n",
            "Epoch 2/5\n",
            "1344/1343 [==============================] - 36s 27ms/step - loss: 0.0585\n",
            "\n",
            "Measuring validation accuracy...\n",
            "14335/14335 [==============================] - 6s 400us/step\n",
            "\n",
            "Validation accuracy: 0.94423\n",
            "\n",
            "Epoch 3/5\n",
            "1344/1343 [==============================] - 36s 27ms/step - loss: 0.0515\n",
            "\n",
            "Measuring validation accuracy...\n",
            "14335/14335 [==============================] - 6s 406us/step\n",
            "\n",
            "Validation accuracy: 0.94559\n",
            "\n",
            "Epoch 4/5\n",
            "1344/1343 [==============================] - 35s 26ms/step - loss: 0.0469\n",
            "\n",
            "Measuring validation accuracy...\n",
            "14335/14335 [==============================] - 6s 405us/step\n",
            "\n",
            "Validation accuracy: 0.94570\n",
            "\n",
            "Epoch 5/5\n",
            "1344/1343 [==============================] - 35s 26ms/step - loss: 0.0429\n",
            "\n",
            "Measuring validation accuracy...\n",
            "14335/14335 [==============================] - 6s 401us/step\n",
            "\n",
            "Validation accuracy: 0.94546\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fbd4a101990>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTN7C34V8aHy"
      },
      "source": [
        "Измерим окончательную accuracy на всем тестовом наборе. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "tHgxnYB68aHy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56a2efd7-363f-4492-ed11-b1088f522dbb"
      },
      "source": [
        "acc = compute_test_accuracy(model)\n",
        "print(\"Final accuracy: %.5f\"%acc)\n",
        "\n",
        "assert acc>0.94, \"Keras has gone on a rampage again, please contact course staff.\""
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14335/14335 [==============================] - 6s 391us/step\n",
            "Final accuracy: 0.94546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5L5Prr4I8aHy"
      },
      "source": [
        "### Bidirectional\n",
        "\n",
        "Поскольку мы анализируем полную последовательность, мы можем смотреть на будущие данные.\n",
        "\n",
        "Простой способ добиться этого — двигаться в обоих направлениях одновременно, создавая __bidirectional RNN__.\n",
        "\n",
        "В Keras вы можете добиться этого как вручную (используя два LSTM и Concatenate), так и с помощью __`keras.layers.Bidirectional`__.\n",
        "\n",
        "Он работает так же, как `TimeDistributed`, который мы видели раньше: вы оборачиваете его вокруг рекуррентного слоя (сейчас SimpleRNN, а позже LSTM/GRU), и он фактически создает два слоя под капотом.\n",
        "\n",
        "Ваша первая задача — использовать такой слой, как наш POS-тегер. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "xWfCrbh-8aHy"
      },
      "source": [
        "# Определите модель, которая использует двунаправленный SimpleRNN \n",
        "model_1 = keras.models.Sequential()\n",
        "\n",
        "model_1 = keras.models.Sequential()\n",
        "model_1.add(L.InputLayer([None],dtype='int32'))\n",
        "model_1.add(L.Embedding(len(all_words),50))\n",
        "\n",
        "bidir = L.SimpleRNN(64, return_sequences=True)\n",
        "bidir = L.Bidirectional(bidir)\n",
        "model_1.add(bidir)\n",
        "\n",
        "# Добавим верхний слой, который предсказывает вероятности тегов \n",
        "stepwise_dense = L.Dense(len(all_tags),activation='softmax')\n",
        "stepwise_dense = L.TimeDistributed(stepwise_dense)\n",
        "model_1.add(stepwise_dense)\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Ort64W348aHz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ed98756-4008-4c93-9819-23aaf31101bf"
      },
      "source": [
        "model_1.compile('adam','categorical_crossentropy')\n",
        "\n",
        "model_1.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n",
        "                    callbacks=[EvaluateAccuracy()], epochs=5,)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1344/1343 [==============================] - 66s 49ms/step - loss: 0.1926\n",
            "\n",
            "Measuring validation accuracy...\n",
            "14335/14335 [==============================] - 11s 749us/step\n",
            "\n",
            "Validation accuracy: 0.95573\n",
            "\n",
            "Epoch 2/5\n",
            "1344/1343 [==============================] - 66s 49ms/step - loss: 0.0426\n",
            "\n",
            "Measuring validation accuracy...\n",
            "14335/14335 [==============================] - 11s 745us/step\n",
            "\n",
            "Validation accuracy: 0.96084\n",
            "\n",
            "Epoch 3/5\n",
            "1344/1343 [==============================] - 65s 48ms/step - loss: 0.0354\n",
            "\n",
            "Measuring validation accuracy...\n",
            "14335/14335 [==============================] - 11s 738us/step\n",
            "\n",
            "Validation accuracy: 0.96236\n",
            "\n",
            "Epoch 4/5\n",
            "1344/1343 [==============================] - 65s 48ms/step - loss: 0.0302\n",
            "\n",
            "Measuring validation accuracy...\n",
            "14335/14335 [==============================] - 11s 744us/step\n",
            "\n",
            "Validation accuracy: 0.96220\n",
            "\n",
            "Epoch 5/5\n",
            "1344/1343 [==============================] - 65s 48ms/step - loss: 0.0256\n",
            "\n",
            "Measuring validation accuracy...\n",
            "14335/14335 [==============================] - 11s 741us/step\n",
            "\n",
            "Validation accuracy: 0.96255\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fbc91daff10>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "iWHSkF648aHz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81df064f-f030-45d9-a0c8-94ac12993371"
      },
      "source": [
        "acc = compute_test_accuracy(model_1)\n",
        "print(\"\\nFinal accuracy: %.5f\"%acc)\n",
        "\n",
        "assert acc>0.96, \"Bidirectional RNNs are better than this!\"\n",
        "print(\"Well done!\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14335/14335 [==============================] - 11s 749us/step\n",
            "\n",
            "Final accuracy: 0.96255\n",
            "Well done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VW_nFppS8aH0"
      },
      "source": [
        "Задача I: Структурированные функции потерь (больше бонусных баллов)\n",
        "\n",
        "Поскольку мы помечаем всю последовательность сразу, мы могли бы также научить нашу сеть делать это. Помните линейную CRF из лекции? Вы также можете использовать его как функцию потерь для вашей RNN.\n",
        "\n",
        "\n",
        "   * Есть несколько способов сделать это, но мы рекомендуем начать с [условных случайных полей](http://blog.echen.me/2012/01/03/introduction-to-conditional-random-fields/)\n",
        "   * Вы можете подключить CRF в качестве функции потерь и по-прежнему тренироваться с помощью обратного распространения. Для вас даже есть аккуратная [реализация] tensorflow (https://www.tensorflow.org/addons/api_docs/python/tfa/layers/CRF).\n",
        "   * Кроме того, вы можете обусловить свою модель предыдущими тегами (сделать ее авторегрессивной) и выполнить __beam search__ по этой модели. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXEj1Nm98aH0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0ffab8c-b815-4042-8ee5-1758f1b436af"
      },
      "source": [
        "pip install git+https://www.github.com/keras-team/keras-contrib.git"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-5lh1mdg3\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-5lh1mdg3\n",
            "Requirement already satisfied: keras in /tensorflow-1.15.2/python3.7 (from keras-contrib==2.0.8) (2.3.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /tensorflow-1.15.2/python3.7 (from keras->keras-contrib==2.0.8) (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.21.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (3.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras->keras-contrib==2.0.8) (1.5.2)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-py3-none-any.whl size=101077 sha256=3ea0ab7d0fac9054c9628cf0be60e7895417fe5d12c0a743e7c9bf770f741e77\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-a4gvo389/wheels/bb/1f/f2/b57495012683b6b20bbae94a3915ec79753111452d79886abc\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "Successfully installed keras-contrib-2.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_contrib.losses import crf_loss\n",
        "from keras_contrib.metrics import crf_accuracy"
      ],
      "metadata": {
        "id": "aSL2su6ADY6r"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Определите модель, которая использует двунаправленный SimpleRNN \n",
        "\n",
        "model_crf = keras.models.Sequential()\n",
        "model_crf.add(L.InputLayer([None],dtype='int32'))\n",
        "model_crf.add(L.Embedding(len(all_words),50))\n",
        "\n",
        "bidir = L.SimpleRNN(64, return_sequences=True)\n",
        "bidir = L.Bidirectional(bidir)\n",
        "model_crf.add(bidir)\n",
        "\n",
        "# Добавим верхний слой, который предсказывает вероятности тегов \n",
        "stepwise_dense = L.Dense(len(all_tags),activation='softmax')\n",
        "# stepwise_dense = L.TimeDistributed(stepwise_dense)\n",
        "model_crf.add(stepwise_dense)"
      ],
      "metadata": {
        "id": "7EUEUQsDDh9S"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_crf.compile(optimizer=\"adam\", loss=crf_loss, metrics=[crf_accuracy])\n",
        "\n",
        "model_crf.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n",
        "                    callbacks=[EvaluateAccuracy()], epochs=5,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "FkDjq_1UDpd-",
        "outputId": "490ca9dc-4bdd-4600-e252-7fd644245eec"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-eddcce510785>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_crf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcrf_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcrf_accuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m model_crf.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n\u001b[1;32m      4\u001b[0m                     callbacks=[EvaluateAccuracy()], epochs=5,)\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mskip_target_masks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_functions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             masks=masks)\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;31m# Compute total loss.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/engine/training.py\u001b[0m in \u001b[0;36m_handle_metrics\u001b[0;34m(self, outputs, targets, skip_target_masks, sample_weights, masks)\u001b[0m\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m                 self._handle_per_output_metrics(\n\u001b[0;32m--> 871\u001b[0;31m                     self._per_output_metrics[i], target, output, output_mask)\n\u001b[0m\u001b[1;32m    872\u001b[0m                 self._handle_per_output_metrics(\n\u001b[1;32m    873\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_per_output_weighted_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/engine/training.py\u001b[0m in \u001b[0;36m_handle_per_output_metrics\u001b[0;34m(self, metrics_dict, y_true, y_pred, mask, weights)\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m                 training_utils.call_metric_function(\n\u001b[0;32m--> 842\u001b[0;31m                     metric_fn, y_true, y_pred, weights=weights, mask=mask)\n\u001b[0m\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m     def _handle_metrics(self,\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcall_metric_function\u001b[0;34m(metric_fn, y_true, y_pred, weights, mask)\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m         \u001b[0mupdate_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1034\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# For TF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m             \u001b[0mmetric_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/utils/metrics_utils.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(metric_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;34m\"\"\"Decorated function with `add_update()`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mupdate_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_state_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mmetric_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdate_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/metrics.py\u001b[0m in \u001b[0;36mupdate_state\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosses_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze_or_expand_dimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         return super(MeanMetricWrapper, self).update_state(\n\u001b[1;32m    320\u001b[0m             matches, sample_weight=sample_weight)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_contrib/metrics/crf_accuracies.py\u001b[0m in \u001b[0;36mcrf_accuracy\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m'''Ge default accuracy based on CRF `test_mode`.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mcrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mcrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'viterbi'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcrf_viterbi_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Dense' object has no attribute 'test_mode'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Bl02uctJDsfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AG_wuMVf8aH0"
      },
      "source": [
        "#### Несколько советов\n",
        "Вот еще несколько советов о том, как улучшить тренировки, которые немного сложнее реализовать. Мы настоятельно рекомендуем вам попробовать их _после_ того, как вы получите хорошую начальную модель.\n",
        "* __Используйте предварительно обученные встраивания__: вы можете использовать предварительно обученные веса из [оттуда](http://ahogrammer.com/2017/01/20/the-list-of-pretrained-word-embeddings/), чтобы запустить встраивание слой.\n",
        "  * Слой внедрения имеет матрицу W (layer.W), которая содержит вложения слов для каждого слова в словаре. Вы можете просто перезаписать их с помощью tf.assign.\n",
        "  * При использовании предварительно обученных эмбеддингов обратите внимание на то, что словарь модели отличается от вашего собственного.\n",
        "  * Вы можете переключить обучаемый = False для встраивания слоя в первые несколько эпох, как при обычной тонкой настройке.\n",
        "* __Выходите за рамки SimpleRNN__: есть keras.layers.LSTM и keras.layers.GRU.\n",
        "  * Если вы хотите использовать пользовательскую рекуррентную ячейку, прочитайте [это](https://keras.io/layers/recurrent/#rnn)\n",
        "  * Вы также можете использовать одномерные свертки (`keras.layers.Conv1D`). Они часто так же хороши, как повторяющиеся слои, но с меньшим переоснащением.\n",
        "* __Сложите больше слоев__: если есть общий мотив для этого курса, то это наложение слоев друг на друга\n",
        "  * Вы можете просто добавить слои recurent и 1dconv друг на друга, и keras это поймет\n",
        "  * Просто помните, что более крупным сетям может потребоваться больше эпох для обучения\n",
        "* __Regularization__: вы можете применять отсев как обычно, но также и в соответствии со специфическими для RNN способами.\n",
        "  * `keras.layers.Dropout` работает между слоями RNN\n",
        "  * Повторяющиеся слои также имеют параметр recurrent_dropout.\n",
        "* __Gradient clipping__: Если ваши тренировки не так стабильны, как вам хотелось бы, установите `clipnorm` в вашем оптимизаторе.\n",
        "  * Другими словами, неплохо следить за кривой потерь для каждой мини-партии. Попробуйте обратный вызов tensorboard или что-то подобное.\n",
        "* __Word Dropout__: tl;dr случайным образом заменяет слова на UNK во время обучения.\n",
        "  * Это также может имитировать увеличение количества неизвестных слов в тестовом наборе.\n",
        "* __Увеличенный словарный запас__: вы можете повысить производительность, расширив входной словарь вашей модели с 5000 до каждого слова!\n",
        "  * Просто убедитесь, что ваша модель не подходит слишком много из-за большого количества параметров.\n",
        "  * В сочетании с регуляризаторами или предварительно обученными векторами слов это может быть действительно хорошо, потому что сейчас наша модель слепа к> 5% слов.\n",
        "* __Более эффективная пакетная обработка__: сейчас TF тратит много времени на перебор \"0\"\n",
        "  * Это происходит потому, что пакет всегда дополняется до длины самого длинного предложения\n",
        "  * Вы можете ускорить процесс, предварительно сгенерировав партии одинаковой длины и заполнив их случайно выбранной предварительно сгенерированной партией.\n",
        "  * Технически это нарушает i.i.d. предположение, но это работает, если вы не придумали какую-нибудь безумную rnn-архитектуру.\n",
        "* __Самый главный совет__: не впихивайте все сразу!\n",
        "  * Если вы добавите много модификаций, некоторые из них почти неизбежно будут вредными, и вы никогда не узнаете, какие из них.\n",
        "  * Вместо этого старайтесь делать небольшие итерации и записывать результаты экспериментов, чтобы ориентироваться в дальнейшем поиске.\n",
        "    \n",
        "Удачной охоты! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TF1T00yr8RvM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}